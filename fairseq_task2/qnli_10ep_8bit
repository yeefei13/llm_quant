{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': json, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': pytorch_ddp, 'ddp_comm_hook': none, 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': never, 'zero_sharding': none, 'fp16': '${common.fp16}', 'memory_efficient_fp16': '${common.memory_efficient_fp16}', 'tpu': '${common.tpu}', 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': 32, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': '${dataset.max_tokens}', 'batch_size_valid': '${dataset.batch_size}', 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': '${dataset.grouped_shuffling}', 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 33112, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/roberta.base/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': '${common.model_parallel_size}'}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': '${distributed_training.distributed_world_size}'}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'dropout': 0.1, 'attention_dropout': 0.1}, 'task': {'_name': 'sentence_prediction', 'data': '/mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin', 'num_classes': 2, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': none, 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': '${criterion.regression_target}', 'classification_head_name': '${criterion.classification_head_name}', 'seed': '${common.seed}', 'd2v2_multi': False}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': False, 'report_mcc': False, 'report_acc_and_f1': False, 'report_pearson_and_spearman': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': '${common.tpu}', 'lr': '${optimization.lr}'}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 1986, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': '${optimization.max_update}', 'lr': '${optimization.lr}'}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
[2024-03-03 20:26:01,331][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': 32, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 33112, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/roberta.base/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'dropout': 0.1, 'attention_dropout': 0.1}, 'task': {'_name': 'sentence_prediction', 'data': '/mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin', 'num_classes': 2, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': none, 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': False, 'classification_head_name': 'sentence_classification_head', 'seed': 1, 'd2v2_multi': False}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': False, 'report_mcc': False, 'report_acc_and_f1': False, 'report_pearson_and_spearman': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 1986, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 33112.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-03-03 20:26:01,422][fairseq.tasks.sentence_prediction][INFO] - [input] dictionary: 50265 types
[2024-03-03 20:26:01,437][fairseq.tasks.sentence_prediction][INFO] - [label] dictionary: 9 types
[2024-03-03 20:26:05,655][fairseq_cli.train][INFO] - RobertaModel(
  (encoder): RobertaEncoder(
    (sentence_encoder): TransformerEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(50265, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-11): 12 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (quantize_input): QuantMeasure()
            (dropout_module): FairseqDropout()
            (k_proj): QLinear(
              in_features=768, out_features=768, bias=True
              (linear): Linear(in_features=768, out_features=768, bias=True)
              (quantize_input): QuantMeasure()
            )
            (v_proj): QLinear(
              in_features=768, out_features=768, bias=True
              (linear): Linear(in_features=768, out_features=768, bias=True)
              (quantize_input): QuantMeasure()
            )
            (q_proj): QLinear(
              in_features=768, out_features=768, bias=True
              (linear): Linear(in_features=768, out_features=768, bias=True)
              (quantize_input): QuantMeasure()
            )
            (out_proj): QLinear(
              in_features=768, out_features=768, bias=True
              (linear): Linear(in_features=768, out_features=768, bias=True)
              (quantize_input): QuantMeasure()
            )
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): QLinear(
            in_features=768, out_features=3072, bias=True
            (linear): Linear(in_features=768, out_features=3072, bias=True)
            (quantize_input): QuantMeasure()
          )
          (fc2): QLinear(
            in_features=3072, out_features=768, bias=True
            (linear): Linear(in_features=3072, out_features=768, bias=True)
            (quantize_input): QuantMeasure()
          )
          (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict(
    (sentence_classification_head): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
[2024-03-03 20:26:05,662][fairseq_cli.train][INFO] - task: SentencePredictionTask
[2024-03-03 20:26:05,663][fairseq_cli.train][INFO] - model: RobertaModel
[2024-03-03 20:26:05,664][fairseq_cli.train][INFO] - criterion: SentencePredictionCriterion
[2024-03-03 20:26:05,666][fairseq_cli.train][INFO] - num. shared model params: 210,306,395 (num. trained: 210,306,395)
[2024-03-03 20:26:05,668][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-03-03 20:26:05,724][fairseq.data.data_utils][INFO] - loaded 5,463 examples from: /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin/input0/valid
[2024-03-03 20:26:05,770][fairseq.data.data_utils][INFO] - loaded 5,463 examples from: /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin/input1/valid
[2024-03-03 20:26:05,824][fairseq.data.data_utils][INFO] - loaded 5,463 examples from: /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin/label/valid
[2024-03-03 20:26:05,825][fairseq.tasks.sentence_prediction][INFO] - Loaded valid with #samples: 5463
MY TRAINER CONFIG! {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': 32, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 33112, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/roberta.base/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'dropout': 0.1, 'attention_dropout': 0.1, 'max_positions': 512, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_dropout': 0.0, 'pooler_dropout': 0.0, 'max_source_positions': 512, 'no_token_positional_embeddings': False, 'encoder_learned_pos': True, 'layernorm_embedding': True, 'no_scale_embedding': True, 'activation_fn': 'gelu', 'encoder_normalize_before': False, 'pooler_activation_fn': 'tanh', 'untie_weights_roberta': False, 'adaptive_input': False, 'encoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'quant_noise_pq': 0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0, 'spectral_norm_classification_head': False}, 'task': {'_name': 'sentence_prediction', 'data': '/mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin', 'num_classes': 2, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': none, 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': False, 'classification_head_name': 'sentence_classification_head', 'seed': 1, 'd2v2_multi': False}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': False, 'report_mcc': False, 'report_acc_and_f1': False, 'report_pearson_and_spearman': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 1986, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 33112.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
MY MODEL!
[2024-03-03 20:26:06,458][fairseq.trainer][INFO] - detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight
[2024-03-03 20:26:06,460][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2024-03-03 20:26:06,461][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 16.000 GB ; name = NVIDIA GeForce RTX 3080 Ti Laptop GPU   
[2024-03-03 20:26:06,462][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2024-03-03 20:26:06,463][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2024-03-03 20:26:06,464][fairseq_cli.train][INFO] - max tokens per device = 4400 and max sentences per device = 32
[2024-03-03 20:26:06,466][fairseq.trainer][INFO] - Preparing to load checkpoint /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/roberta.base/model.pt
[2024-03-03 20:26:14,976][fairseq.models.roberta.model][INFO] - Overwriting classification_heads.sentence_classification_head.dense.weight
[2024-03-03 20:26:14,977][fairseq.models.roberta.model][INFO] - Overwriting classification_heads.sentence_classification_head.dense.bias
[2024-03-03 20:26:14,978][fairseq.models.roberta.model][INFO] - Overwriting classification_heads.sentence_classification_head.out_proj.weight
[2024-03-03 20:26:14,978][fairseq.models.roberta.model][INFO] - Overwriting classification_heads.sentence_classification_head.out_proj.bias
[2024-03-03 20:26:15,267][fairseq.trainer][INFO] - NOTE: your device may support faster training with --fp16 or --amp
[2024-03-03 20:26:15,274][fairseq.optim.adam][INFO] - using FusedAdam
[2024-03-03 20:26:15,913][fairseq.trainer][INFO] - Loaded checkpoint /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/roberta.base/model.pt (epoch 1 @ 0 updates)
[2024-03-03 20:26:15,914][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-03-03 20:26:15,971][fairseq.data.data_utils][INFO] - loaded 104,743 examples from: /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin/input0/train
[2024-03-03 20:26:16,047][fairseq.data.data_utils][INFO] - loaded 104,743 examples from: /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin/input1/train
[2024-03-03 20:26:16,173][fairseq.data.data_utils][INFO] - loaded 104,743 examples from: /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/QNLI-bin/label/train
[2024-03-03 20:26:16,176][fairseq.tasks.sentence_prediction][INFO] - Loaded train with #samples: 104743
[2024-03-03 20:26:16,179][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 20:26:16,180][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-03-03 20:26:16,181][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-03-03 20:26:16,182][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-03-03 20:26:16,197][fairseq.tasks.fairseq_task][WARNING] - 5 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[84277, 88427, 82398, 2711, 82549]
[2024-03-03 20:26:16,553][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2024-03-03 20:26:16,554][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 20:26:16,555][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2024-03-03 20:26:16,556][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2024-03-03 20:26:16,557][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2024-03-03 20:26:19,139][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 20:26:19,144][fairseq.trainer][INFO] - begin training epoch 1
[2024-03-03 20:26:19,147][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 20:28:06,967][train_inner][INFO] - {"epoch": 1, "update": 0.06, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "3013", "ups": "1.88", "wpb": "1603.7", "bsz": "31.6", "num_updates": "200", "lr": "1.00705e-06", "gnorm": "0", "train_wall": "107", "gb_free": "15.1", "wall": "121"}
[2024-03-03 20:32:54,535][train_inner][INFO] - {"epoch": 1, "update": 0.12, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "1121.9", "ups": "0.7", "wpb": "1613.1", "bsz": "31.5", "num_updates": "400", "lr": "2.0141e-06", "gnorm": "0", "train_wall": "287", "gb_free": "15.1", "wall": "408"}
[2024-03-03 20:39:52,873][train_inner][INFO] - {"epoch": 1, "update": 0.18, "loss": "0", "nll_loss": "0", "accuracy": "50.3", "wps": "760.5", "ups": "0.48", "wpb": "1590.7", "bsz": "31.3", "num_updates": "600", "lr": "3.02115e-06", "gnorm": "0", "train_wall": "418", "gb_free": "15.1", "wall": "826"}
[2024-03-03 20:45:52,990][train_inner][INFO] - {"epoch": 1, "update": 0.24, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "887", "ups": "0.56", "wpb": "1597.1", "bsz": "31.3", "num_updates": "800", "lr": "4.0282e-06", "gnorm": "0", "train_wall": "359", "gb_free": "15.1", "wall": "1187"}
[2024-03-03 20:50:41,837][train_inner][INFO] - {"epoch": 1, "update": 0.3, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "1110.9", "ups": "0.69", "wpb": "1604.3", "bsz": "31.5", "num_updates": "1000", "lr": "5.03525e-06", "gnorm": "0", "train_wall": "288", "gb_free": "15", "wall": "1475"}
[2024-03-03 20:55:37,441][train_inner][INFO] - {"epoch": 1, "update": 0.36, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "1083.7", "ups": "0.68", "wpb": "1601.8", "bsz": "31.5", "num_updates": "1200", "lr": "6.0423e-06", "gnorm": "0", "train_wall": "295", "gb_free": "15.1", "wall": "1771"}
[2024-03-03 21:04:36,649][train_inner][INFO] - {"epoch": 1, "update": 0.42, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "597.7", "ups": "0.37", "wpb": "1611.4", "bsz": "31.7", "num_updates": "1400", "lr": "7.04935e-06", "gnorm": "0", "train_wall": "539", "gb_free": "15.1", "wall": "2310"}
[2024-03-03 21:07:08,906][train_inner][INFO] - {"epoch": 1, "update": 0.48, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "2101.6", "ups": "1.31", "wpb": "1599.9", "bsz": "31.5", "num_updates": "1600", "lr": "8.05639e-06", "gnorm": "0", "train_wall": "151", "gb_free": "15.1", "wall": "2462"}
[2024-03-03 21:11:42,467][train_inner][INFO] - {"epoch": 1, "update": 0.541, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "1163.6", "ups": "0.73", "wpb": "1591.5", "bsz": "31.2", "num_updates": "1800", "lr": "9.06344e-06", "gnorm": "0", "train_wall": "273", "gb_free": "15", "wall": "2736"}
[2024-03-03 21:18:23,231][train_inner][INFO] - {"epoch": 1, "update": 0.601, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "793", "ups": "0.5", "wpb": "1588.9", "bsz": "31.3", "num_updates": "2000", "lr": "9.9955e-06", "gnorm": "0", "train_wall": "400", "gb_free": "15.1", "wall": "3137"}
[2024-03-03 21:23:26,036][train_inner][INFO] - {"epoch": 1, "update": 0.661, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "1066.1", "ups": "0.66", "wpb": "1614.1", "bsz": "31.4", "num_updates": "2200", "lr": "9.93125e-06", "gnorm": "0", "train_wall": "302", "gb_free": "15.1", "wall": "3440"}
[2024-03-03 21:27:19,636][train_inner][INFO] - {"epoch": 1, "update": 0.721, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "1378.1", "ups": "0.86", "wpb": "1609.7", "bsz": "31.4", "num_updates": "2400", "lr": "9.86699e-06", "gnorm": "0", "train_wall": "233", "gb_free": "15.1", "wall": "3673"}
[2024-03-03 21:29:10,670][train_inner][INFO] - {"epoch": 1, "update": 0.781, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "2880.3", "ups": "1.8", "wpb": "1599.1", "bsz": "31.6", "num_updates": "2600", "lr": "9.80274e-06", "gnorm": "0", "train_wall": "110", "gb_free": "15.1", "wall": "3784"}
[2024-03-03 21:30:14,574][train_inner][INFO] - {"epoch": 1, "update": 0.841, "loss": "0", "nll_loss": "0", "accuracy": "50.5", "wps": "5041.8", "ups": "3.13", "wpb": "1610.9", "bsz": "31.6", "num_updates": "2800", "lr": "9.73848e-06", "gnorm": "0", "train_wall": "63", "gb_free": "15.1", "wall": "3848"}
[2024-03-03 21:31:19,621][train_inner][INFO] - {"epoch": 1, "update": 0.901, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "4962.4", "ups": "3.07", "wpb": "1613.9", "bsz": "31.6", "num_updates": "3000", "lr": "9.67423e-06", "gnorm": "0", "train_wall": "64", "gb_free": "15.1", "wall": "3913"}
[2024-03-03 21:32:35,396][train_inner][INFO] - {"epoch": 1, "update": 0.961, "loss": "0", "nll_loss": "0", "accuracy": "47.9", "wps": "4217.8", "ups": "2.64", "wpb": "1598", "bsz": "31.5", "num_updates": "3200", "lr": "9.60997e-06", "gnorm": "0", "train_wall": "75", "gb_free": "15.1", "wall": "3989"}
[2024-03-03 21:33:29,010][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 21:33:29,018][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 21:34:24,632][valid][INFO] - {"epoch": 1, "valid_loss": "1.004", "valid_nll_loss": "0.019", "valid_accuracy": "50.7", "valid_wps": "5133.3", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "3330"}
[2024-03-03 21:34:24,639][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 3330 updates
[2024-03-03 21:34:24,643][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 21:34:28,125][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 21:35:28,558][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 3330 updates, score 50.7) (writing took 63.91874047500005 seconds)
[2024-03-03 21:35:28,559][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-03-03 21:35:28,565][train][INFO] - {"epoch": 1, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.5", "train_wps": "1285.9", "train_ups": "0.8", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "3330", "train_lr": "9.56821e-06", "train_gnorm": "0", "train_train_wall": "4018", "train_gb_free": "15", "train_wall": "4162"}
[2024-03-03 21:35:28,576][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 21:35:28,591][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 21:35:28,597][fairseq.trainer][INFO] - begin training epoch 2
[2024-03-03 21:35:28,599][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 21:35:59,603][train_inner][INFO] - {"epoch": 2, "update": 1.021, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "1542.9", "ups": "0.98", "wpb": "1575.4", "bsz": "31", "num_updates": "3400", "lr": "9.54572e-06", "gnorm": "0", "train_wall": "84", "gb_free": "15.1", "wall": "4193"}
[2024-03-03 21:37:23,045][train_inner][INFO] - {"epoch": 2, "update": 1.081, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "3841.8", "ups": "2.4", "wpb": "1602.8", "bsz": "31.4", "num_updates": "3600", "lr": "9.48146e-06", "gnorm": "0", "train_wall": "83", "gb_free": "15.1", "wall": "4277"}
[2024-03-03 21:38:35,326][train_inner][INFO] - {"epoch": 2, "update": 1.141, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "4417.9", "ups": "2.77", "wpb": "1596.6", "bsz": "31.5", "num_updates": "3800", "lr": "9.41721e-06", "gnorm": "0", "train_wall": "72", "gb_free": "15.1", "wall": "4349"}
[2024-03-03 21:39:38,741][train_inner][INFO] - {"epoch": 2, "update": 1.201, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "5074.1", "ups": "3.15", "wpb": "1608.8", "bsz": "31.5", "num_updates": "4000", "lr": "9.35295e-06", "gnorm": "0", "train_wall": "63", "gb_free": "15.1", "wall": "4412"}
[2024-03-03 21:41:00,657][train_inner][INFO] - {"epoch": 2, "update": 1.261, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "3926.6", "ups": "2.44", "wpb": "1608.2", "bsz": "31.6", "num_updates": "4200", "lr": "9.2887e-06", "gnorm": "0", "train_wall": "81", "gb_free": "15", "wall": "4494"}
[2024-03-03 21:42:27,477][train_inner][INFO] - {"epoch": 2, "update": 1.321, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "3707.1", "ups": "2.3", "wpb": "1609.2", "bsz": "31.6", "num_updates": "4400", "lr": "9.22444e-06", "gnorm": "0", "train_wall": "86", "gb_free": "15.1", "wall": "4581"}
[2024-03-03 21:43:57,573][train_inner][INFO] - {"epoch": 2, "update": 1.381, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "3541.5", "ups": "2.22", "wpb": "1595.3", "bsz": "31.2", "num_updates": "4600", "lr": "9.16019e-06", "gnorm": "0", "train_wall": "89", "gb_free": "15.1", "wall": "4671"}
[2024-03-03 21:45:17,199][train_inner][INFO] - {"epoch": 2, "update": 1.441, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "4048.3", "ups": "2.51", "wpb": "1611.7", "bsz": "31.5", "num_updates": "4800", "lr": "9.09593e-06", "gnorm": "0", "train_wall": "79", "gb_free": "15", "wall": "4751"}
[2024-03-03 21:46:35,631][train_inner][INFO] - {"epoch": 2, "update": 1.502, "loss": "0", "nll_loss": "0", "accuracy": "48.7", "wps": "4074.4", "ups": "2.55", "wpb": "1597.8", "bsz": "31.5", "num_updates": "5000", "lr": "9.03168e-06", "gnorm": "0", "train_wall": "78", "gb_free": "15.1", "wall": "4829"}
[2024-03-03 21:47:48,857][train_inner][INFO] - {"epoch": 2, "update": 1.562, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "4359", "ups": "2.73", "wpb": "1595.9", "bsz": "31.2", "num_updates": "5200", "lr": "8.96742e-06", "gnorm": "0", "train_wall": "72", "gb_free": "15.1", "wall": "4902"}
[2024-03-03 21:48:46,085][train_inner][INFO] - {"epoch": 2, "update": 1.622, "loss": "0", "nll_loss": "0", "accuracy": "51", "wps": "5559.5", "ups": "3.49", "wpb": "1590.8", "bsz": "31.5", "num_updates": "5400", "lr": "8.90317e-06", "gnorm": "0", "train_wall": "56", "gb_free": "15.1", "wall": "4960"}
[2024-03-03 21:49:51,534][train_inner][INFO] - {"epoch": 2, "update": 1.682, "loss": "0", "nll_loss": "0", "accuracy": "48.6", "wps": "4920.1", "ups": "3.06", "wpb": "1610", "bsz": "31.8", "num_updates": "5600", "lr": "8.83891e-06", "gnorm": "0", "train_wall": "65", "gb_free": "15.1", "wall": "5025"}
[2024-03-03 21:51:01,747][train_inner][INFO] - {"epoch": 2, "update": 1.742, "loss": "0", "nll_loss": "0", "accuracy": "48.6", "wps": "4592.5", "ups": "2.85", "wpb": "1612.2", "bsz": "31.5", "num_updates": "5800", "lr": "8.77466e-06", "gnorm": "0", "train_wall": "70", "gb_free": "15.1", "wall": "5095"}
[2024-03-03 21:52:06,887][train_inner][INFO] - {"epoch": 2, "update": 1.802, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "4910", "ups": "3.07", "wpb": "1599.1", "bsz": "31.3", "num_updates": "6000", "lr": "8.7104e-06", "gnorm": "0", "train_wall": "64", "gb_free": "15", "wall": "5160"}
[2024-03-03 21:53:02,827][train_inner][INFO] - {"epoch": 2, "update": 1.862, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "5792", "ups": "3.58", "wpb": "1619.9", "bsz": "31.7", "num_updates": "6200", "lr": "8.64615e-06", "gnorm": "0", "train_wall": "55", "gb_free": "15.1", "wall": "5216"}
[2024-03-03 21:53:58,301][train_inner][INFO] - {"epoch": 2, "update": 1.922, "loss": "0", "nll_loss": "0", "accuracy": "49.9", "wps": "5789.6", "ups": "3.61", "wpb": "1605.8", "bsz": "31.6", "num_updates": "6400", "lr": "8.58189e-06", "gnorm": "0", "train_wall": "55", "gb_free": "15.1", "wall": "5272"}
[2024-03-03 21:54:54,589][train_inner][INFO] - {"epoch": 2, "update": 1.982, "loss": "0", "nll_loss": "0", "accuracy": "50.5", "wps": "5657", "ups": "3.55", "wpb": "1592.1", "bsz": "31.3", "num_updates": "6600", "lr": "8.51764e-06", "gnorm": "0", "train_wall": "56", "gb_free": "15", "wall": "5328"}
[2024-03-03 21:55:11,678][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 21:55:11,682][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 21:55:58,673][valid][INFO] - {"epoch": 2, "valid_loss": "1.004", "valid_nll_loss": "0.019", "valid_accuracy": "50.7", "valid_wps": "6065.9", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "6660", "valid_best_accuracy": "50.7"}
[2024-03-03 21:55:58,676][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 6660 updates
[2024-03-03 21:55:58,677][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 21:56:01,852][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 21:56:50,402][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 6660 updates, score 50.7) (writing took 51.725470841999595 seconds)
[2024-03-03 21:56:50,403][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-03-03 21:56:50,405][train][INFO] - {"epoch": 2, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.5", "train_wps": "4162", "train_ups": "2.6", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "6660", "train_lr": "8.49836e-06", "train_gnorm": "0", "train_train_wall": "1170", "train_gb_free": "15.1", "train_wall": "5444"}
[2024-03-03 21:56:50,408][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 21:56:50,417][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 21:56:50,423][fairseq.trainer][INFO] - begin training epoch 3
[2024-03-03 21:56:50,425][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 21:57:29,141][train_inner][INFO] - {"epoch": 3, "update": 2.042, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "2079.1", "ups": "1.29", "wpb": "1606.7", "bsz": "31.5", "num_updates": "6800", "lr": "8.45338e-06", "gnorm": "0", "train_wall": "55", "gb_free": "15", "wall": "5483"}
[2024-03-03 21:58:26,572][train_inner][INFO] - {"epoch": 3, "update": 2.102, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "5610.9", "ups": "3.48", "wpb": "1611.2", "bsz": "31.5", "num_updates": "7000", "lr": "8.38913e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15.1", "wall": "5540"}
[2024-03-03 21:59:25,058][train_inner][INFO] - {"epoch": 3, "update": 2.162, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "5470.8", "ups": "3.42", "wpb": "1599.8", "bsz": "31.4", "num_updates": "7200", "lr": "8.32487e-06", "gnorm": "0", "train_wall": "58", "gb_free": "15", "wall": "5599"}
[2024-03-03 22:00:20,091][train_inner][INFO] - {"epoch": 3, "update": 2.222, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "5794.5", "ups": "3.63", "wpb": "1594.4", "bsz": "31.4", "num_updates": "7400", "lr": "8.26062e-06", "gnorm": "0", "train_wall": "55", "gb_free": "15.1", "wall": "5654"}
[2024-03-03 22:01:17,399][train_inner][INFO] - {"epoch": 3, "update": 2.282, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "5610.8", "ups": "3.49", "wpb": "1607.7", "bsz": "31.6", "num_updates": "7600", "lr": "8.19636e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15", "wall": "5711"}
[2024-03-03 22:02:15,313][train_inner][INFO] - {"epoch": 3, "update": 2.342, "loss": "0", "nll_loss": "0", "accuracy": "48.1", "wps": "5556.6", "ups": "3.45", "wpb": "1609", "bsz": "31.5", "num_updates": "7800", "lr": "8.13211e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15.1", "wall": "5769"}
[2024-03-03 22:03:13,650][train_inner][INFO] - {"epoch": 3, "update": 2.402, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "5462.3", "ups": "3.43", "wpb": "1593.2", "bsz": "31.2", "num_updates": "8000", "lr": "8.06785e-06", "gnorm": "0", "train_wall": "58", "gb_free": "15.1", "wall": "5827"}
[2024-03-03 22:04:11,612][train_inner][INFO] - {"epoch": 3, "update": 2.462, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "5501.7", "ups": "3.45", "wpb": "1594.4", "bsz": "31.5", "num_updates": "8200", "lr": "8.0036e-06", "gnorm": "0", "train_wall": "58", "gb_free": "15", "wall": "5885"}
[2024-03-03 22:05:06,964][train_inner][INFO] - {"epoch": 3, "update": 2.523, "loss": "0", "nll_loss": "0", "accuracy": "48.1", "wps": "5841", "ups": "3.61", "wpb": "1616.5", "bsz": "31.6", "num_updates": "8400", "lr": "7.93934e-06", "gnorm": "0", "train_wall": "55", "gb_free": "15.1", "wall": "5941"}
[2024-03-03 22:06:04,246][train_inner][INFO] - {"epoch": 3, "update": 2.583, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "5619.6", "ups": "3.49", "wpb": "1609.5", "bsz": "31.6", "num_updates": "8600", "lr": "7.87509e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15.1", "wall": "5998"}
[2024-03-03 22:07:02,510][train_inner][INFO] - {"epoch": 3, "update": 2.643, "loss": "0", "nll_loss": "0", "accuracy": "50.2", "wps": "5487.1", "ups": "3.43", "wpb": "1598.5", "bsz": "31.4", "num_updates": "8800", "lr": "7.81083e-06", "gnorm": "0", "train_wall": "58", "gb_free": "15", "wall": "6056"}
[2024-03-03 22:08:00,440][train_inner][INFO] - {"epoch": 3, "update": 2.703, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "5498.1", "ups": "3.45", "wpb": "1592.5", "bsz": "31.5", "num_updates": "9000", "lr": "7.74658e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15", "wall": "6114"}
[2024-03-03 22:08:57,910][train_inner][INFO] - {"epoch": 3, "update": 2.763, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "5572.3", "ups": "3.48", "wpb": "1601.1", "bsz": "31.4", "num_updates": "9200", "lr": "7.68232e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15.1", "wall": "6171"}
[2024-03-03 22:09:52,036][train_inner][INFO] - {"epoch": 3, "update": 2.823, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "5992.6", "ups": "3.7", "wpb": "1621.7", "bsz": "31.6", "num_updates": "9400", "lr": "7.61807e-06", "gnorm": "0", "train_wall": "54", "gb_free": "15.1", "wall": "6226"}
[2024-03-03 22:10:50,138][train_inner][INFO] - {"epoch": 3, "update": 2.883, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "5499.7", "ups": "3.44", "wpb": "1597.7", "bsz": "31.5", "num_updates": "9600", "lr": "7.55381e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15.1", "wall": "6284"}
[2024-03-03 22:11:48,259][train_inner][INFO] - {"epoch": 3, "update": 2.943, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "5461.9", "ups": "3.44", "wpb": "1587.2", "bsz": "31.1", "num_updates": "9800", "lr": "7.48956e-06", "gnorm": "0", "train_wall": "57", "gb_free": "15.1", "wall": "6342"}
[2024-03-03 22:12:41,458][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 22:12:41,460][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:13:30,653][valid][INFO] - {"epoch": 3, "valid_loss": "1.004", "valid_nll_loss": "0.019", "valid_accuracy": "50.6", "valid_wps": "5794", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "9990", "valid_best_accuracy": "50.7"}
[2024-03-03 22:13:30,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 9990 updates
[2024-03-03 22:13:30,659][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:13:34,502][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:13:34,505][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 3 @ 9990 updates, score 50.6) (writing took 3.8480963990004966 seconds)
[2024-03-03 22:13:34,507][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-03-03 22:13:34,509][train][INFO] - {"epoch": 3, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.3", "train_wps": "5313.3", "train_ups": "3.32", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "9990", "train_lr": "7.42852e-06", "train_gnorm": "0", "train_train_wall": "943", "train_gb_free": "15.1", "train_wall": "6448"}
[2024-03-03 22:13:34,513][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:13:34,523][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 22:13:34,530][fairseq.trainer][INFO] - begin training epoch 4
[2024-03-03 22:13:34,532][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 22:13:38,213][train_inner][INFO] - {"epoch": 4, "update": 3.003, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "2885.7", "ups": "1.82", "wpb": "1586.4", "bsz": "31.3", "num_updates": "10000", "lr": "7.4253e-06", "gnorm": "0", "train_wall": "56", "gb_free": "15", "wall": "6452"}
[2024-03-03 22:14:58,148][train_inner][INFO] - {"epoch": 4, "update": 3.063, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "3991.1", "ups": "2.5", "wpb": "1595.1", "bsz": "31.3", "num_updates": "10200", "lr": "7.36105e-06", "gnorm": "0", "train_wall": "79", "gb_free": "15.1", "wall": "6532"}
[2024-03-03 22:15:47,940][train_inner][INFO] - {"epoch": 4, "update": 3.123, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "6448.5", "ups": "4.02", "wpb": "1605.4", "bsz": "31.4", "num_updates": "10400", "lr": "7.29679e-06", "gnorm": "0", "train_wall": "49", "gb_free": "15.1", "wall": "6581"}
[2024-03-03 22:17:08,099][train_inner][INFO] - {"epoch": 4, "update": 3.183, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "4001.4", "ups": "2.5", "wpb": "1603.7", "bsz": "31.6", "num_updates": "10600", "lr": "7.23254e-06", "gnorm": "0", "train_wall": "79", "gb_free": "15.1", "wall": "6662"}
[2024-03-03 22:18:38,393][train_inner][INFO] - {"epoch": 4, "update": 3.243, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "3582.1", "ups": "2.22", "wpb": "1617.2", "bsz": "31.6", "num_updates": "10800", "lr": "7.16828e-06", "gnorm": "0", "train_wall": "89", "gb_free": "15.1", "wall": "6752"}
[2024-03-03 22:20:08,717][train_inner][INFO] - {"epoch": 4, "update": 3.303, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "3517.3", "ups": "2.21", "wpb": "1588.5", "bsz": "31.3", "num_updates": "11000", "lr": "7.10403e-06", "gnorm": "0", "train_wall": "89", "gb_free": "15.1", "wall": "6842"}
[2024-03-03 22:21:30,199][train_inner][INFO] - {"epoch": 4, "update": 3.363, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "3950.1", "ups": "2.45", "wpb": "1609.3", "bsz": "31.6", "num_updates": "11200", "lr": "7.03977e-06", "gnorm": "0", "train_wall": "81", "gb_free": "15.1", "wall": "6924"}
[2024-03-03 22:22:38,138][train_inner][INFO] - {"epoch": 4, "update": 3.423, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "4698.5", "ups": "2.94", "wpb": "1596", "bsz": "31.5", "num_updates": "11400", "lr": "6.97552e-06", "gnorm": "0", "train_wall": "67", "gb_free": "15", "wall": "6992"}
[2024-03-03 22:23:33,322][train_inner][INFO] - {"epoch": 4, "update": 3.483, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "5847", "ups": "3.62", "wpb": "1613.3", "bsz": "31.3", "num_updates": "11600", "lr": "6.91126e-06", "gnorm": "0", "train_wall": "55", "gb_free": "15.1", "wall": "7047"}
[2024-03-03 22:24:45,329][train_inner][INFO] - {"epoch": 4, "update": 3.544, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "4442.5", "ups": "2.78", "wpb": "1599.4", "bsz": "31.5", "num_updates": "11800", "lr": "6.84701e-06", "gnorm": "0", "train_wall": "71", "gb_free": "15.1", "wall": "7119"}
[2024-03-03 22:25:56,984][train_inner][INFO] - {"epoch": 4, "update": 3.604, "loss": "0", "nll_loss": "0", "accuracy": "50.7", "wps": "4473.7", "ups": "2.79", "wpb": "1602.8", "bsz": "31.5", "num_updates": "12000", "lr": "6.78275e-06", "gnorm": "0", "train_wall": "71", "gb_free": "15.1", "wall": "7191"}
[2024-03-03 22:27:10,193][train_inner][INFO] - {"epoch": 4, "update": 3.664, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "4365.3", "ups": "2.73", "wpb": "1597.8", "bsz": "31.4", "num_updates": "12200", "lr": "6.7185e-06", "gnorm": "0", "train_wall": "73", "gb_free": "15.1", "wall": "7264"}
[2024-03-03 22:28:23,735][train_inner][INFO] - {"epoch": 4, "update": 3.724, "loss": "0", "nll_loss": "0", "accuracy": "50.8", "wps": "4338.4", "ups": "2.72", "wpb": "1595.2", "bsz": "31.4", "num_updates": "12400", "lr": "6.65424e-06", "gnorm": "0", "train_wall": "73", "gb_free": "15.1", "wall": "7337"}
[2024-03-03 22:29:12,261][train_inner][INFO] - {"epoch": 4, "update": 3.784, "loss": "0", "nll_loss": "0", "accuracy": "50.2", "wps": "6599.4", "ups": "4.12", "wpb": "1601.2", "bsz": "31.3", "num_updates": "12600", "lr": "6.58999e-06", "gnorm": "0", "train_wall": "48", "gb_free": "15.1", "wall": "7386"}
[2024-03-03 22:29:59,231][train_inner][INFO] - {"epoch": 4, "update": 3.844, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "6805.7", "ups": "4.26", "wpb": "1598.3", "bsz": "31.4", "num_updates": "12800", "lr": "6.52573e-06", "gnorm": "0", "train_wall": "46", "gb_free": "15.1", "wall": "7433"}
[2024-03-03 22:30:50,117][train_inner][INFO] - {"epoch": 4, "update": 3.904, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "6311.8", "ups": "3.93", "wpb": "1605.9", "bsz": "31.6", "num_updates": "13000", "lr": "6.46148e-06", "gnorm": "0", "train_wall": "50", "gb_free": "15.1", "wall": "7484"}
[2024-03-03 22:31:39,113][train_inner][INFO] - {"epoch": 4, "update": 3.964, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "6586.6", "ups": "4.08", "wpb": "1613.5", "bsz": "31.7", "num_updates": "13200", "lr": "6.39722e-06", "gnorm": "0", "train_wall": "48", "gb_free": "15.1", "wall": "7533"}
[2024-03-03 22:31:58,551][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 22:31:58,553][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:32:24,324][valid][INFO] - {"epoch": 4, "valid_loss": "1.004", "valid_nll_loss": "0.019", "valid_accuracy": "50.8", "valid_wps": "11063.2", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "13320", "valid_best_accuracy": "50.8"}
[2024-03-03 22:32:24,328][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 13320 updates
[2024-03-03 22:32:24,330][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 22:32:26,897][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 22:33:15,453][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 13320 updates, score 50.8) (writing took 51.12461567099854 seconds)
[2024-03-03 22:33:15,454][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-03-03 22:33:15,457][train][INFO] - {"epoch": 4, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.9", "train_wps": "4517.6", "train_ups": "2.82", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "13320", "train_lr": "6.35867e-06", "train_gnorm": "0", "train_train_wall": "1092", "train_gb_free": "15.1", "train_wall": "7629"}
[2024-03-03 22:33:15,460][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:33:15,467][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 22:33:15,471][fairseq.trainer][INFO] - begin training epoch 5
[2024-03-03 22:33:15,472][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 22:33:26,759][train_inner][INFO] - {"epoch": 5, "update": 4.024, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "2954.1", "ups": "1.86", "wpb": "1589.9", "bsz": "31.4", "num_updates": "13400", "lr": "6.33297e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "7640"}
[2024-03-03 22:33:55,476][train_inner][INFO] - {"epoch": 5, "update": 4.084, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "11248.6", "ups": "6.96", "wpb": "1615.1", "bsz": "31.5", "num_updates": "13600", "lr": "6.26871e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "7669"}
[2024-03-03 22:34:24,201][train_inner][INFO] - {"epoch": 5, "update": 4.144, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "11193.4", "ups": "6.96", "wpb": "1607.6", "bsz": "31.6", "num_updates": "13800", "lr": "6.20446e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "7698"}
[2024-03-03 22:34:53,120][train_inner][INFO] - {"epoch": 5, "update": 4.204, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "11104.3", "ups": "6.92", "wpb": "1605.5", "bsz": "31.5", "num_updates": "14000", "lr": "6.1402e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "7727"}
[2024-03-03 22:35:23,026][train_inner][INFO] - {"epoch": 5, "update": 4.264, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "10632.6", "ups": "6.69", "wpb": "1589.8", "bsz": "31.2", "num_updates": "14200", "lr": "6.07595e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "7757"}
[2024-03-03 22:35:53,524][train_inner][INFO] - {"epoch": 5, "update": 4.324, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "10561.3", "ups": "6.56", "wpb": "1610.4", "bsz": "31.7", "num_updates": "14400", "lr": "6.01169e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "7787"}
[2024-03-03 22:36:24,841][train_inner][INFO] - {"epoch": 5, "update": 4.384, "loss": "0", "nll_loss": "0", "accuracy": "47.9", "wps": "10269.1", "ups": "6.39", "wpb": "1607.9", "bsz": "31.4", "num_updates": "14600", "lr": "5.94744e-06", "gnorm": "0", "train_wall": "31", "gb_free": "15.1", "wall": "7818"}
[2024-03-03 22:36:55,196][train_inner][INFO] - {"epoch": 5, "update": 4.444, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "10405.5", "ups": "6.59", "wpb": "1579.3", "bsz": "31.4", "num_updates": "14800", "lr": "5.88318e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "7849"}
[2024-03-03 22:37:26,216][train_inner][INFO] - {"epoch": 5, "update": 4.505, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "10299.1", "ups": "6.45", "wpb": "1597.3", "bsz": "31.4", "num_updates": "15000", "lr": "5.81893e-06", "gnorm": "0", "train_wall": "31", "gb_free": "15.1", "wall": "7880"}
[2024-03-03 22:37:56,873][train_inner][INFO] - {"epoch": 5, "update": 4.565, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "10506.3", "ups": "6.52", "wpb": "1610.4", "bsz": "31.6", "num_updates": "15200", "lr": "5.75467e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15", "wall": "7910"}
[2024-03-03 22:38:27,785][train_inner][INFO] - {"epoch": 5, "update": 4.625, "loss": "0", "nll_loss": "0", "accuracy": "50.9", "wps": "10385.5", "ups": "6.47", "wpb": "1605.1", "bsz": "31.2", "num_updates": "15400", "lr": "5.69042e-06", "gnorm": "0", "train_wall": "31", "gb_free": "15.1", "wall": "7941"}
[2024-03-03 22:38:58,187][train_inner][INFO] - {"epoch": 5, "update": 4.685, "loss": "0", "nll_loss": "0", "accuracy": "48.6", "wps": "10519.2", "ups": "6.58", "wpb": "1599", "bsz": "31.5", "num_updates": "15600", "lr": "5.62616e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "7972"}
[2024-03-03 22:39:28,885][train_inner][INFO] - {"epoch": 5, "update": 4.745, "loss": "0", "nll_loss": "0", "accuracy": "50.9", "wps": "10417.8", "ups": "6.52", "wpb": "1599", "bsz": "31.5", "num_updates": "15800", "lr": "5.56191e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8002"}
[2024-03-03 22:40:00,055][train_inner][INFO] - {"epoch": 5, "update": 4.805, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "10365.6", "ups": "6.42", "wpb": "1615.4", "bsz": "31.5", "num_updates": "16000", "lr": "5.49765e-06", "gnorm": "0", "train_wall": "31", "gb_free": "15.1", "wall": "8034"}
[2024-03-03 22:40:30,984][train_inner][INFO] - {"epoch": 5, "update": 4.865, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "10309.1", "ups": "6.47", "wpb": "1594.2", "bsz": "31.3", "num_updates": "16200", "lr": "5.4334e-06", "gnorm": "0", "train_wall": "31", "gb_free": "15", "wall": "8065"}
[2024-03-03 22:41:01,877][train_inner][INFO] - {"epoch": 5, "update": 4.925, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "10343.1", "ups": "6.47", "wpb": "1597.6", "bsz": "31.5", "num_updates": "16400", "lr": "5.36914e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8095"}
[2024-03-03 22:41:32,537][train_inner][INFO] - {"epoch": 5, "update": 4.985, "loss": "0", "nll_loss": "0", "accuracy": "50.5", "wps": "10429.4", "ups": "6.52", "wpb": "1598.8", "bsz": "31.4", "num_updates": "16600", "lr": "5.30489e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8126"}
[2024-03-03 22:41:40,017][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 22:41:40,019][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:42:05,983][valid][INFO] - {"epoch": 5, "valid_loss": "1.003", "valid_nll_loss": "0.019", "valid_accuracy": "50.6", "valid_wps": "10976.5", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "16650", "valid_best_accuracy": "50.8"}
[2024-03-03 22:42:05,987][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 16650 updates
[2024-03-03 22:42:05,989][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:42:08,581][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:42:08,583][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 5 @ 16650 updates, score 50.6) (writing took 2.596300520999648 seconds)
[2024-03-03 22:42:08,585][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-03-03 22:42:08,588][train][INFO] - {"epoch": 5, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.6", "train_wps": "10007.1", "train_ups": "6.25", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "16650", "train_lr": "5.28883e-06", "train_gnorm": "0", "train_train_wall": "498", "train_gb_free": "15.1", "train_wall": "8162"}
[2024-03-03 22:42:08,590][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:42:08,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 22:42:08,599][fairseq.trainer][INFO] - begin training epoch 6
[2024-03-03 22:42:08,600][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 22:42:31,937][train_inner][INFO] - {"epoch": 6, "update": 5.045, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "5397.8", "ups": "3.37", "wpb": "1603.1", "bsz": "31.2", "num_updates": "16800", "lr": "5.24063e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8185"}
[2024-03-03 22:43:02,979][train_inner][INFO] - {"epoch": 6, "update": 5.105, "loss": "0", "nll_loss": "0", "accuracy": "49.9", "wps": "10266.2", "ups": "6.44", "wpb": "1593.4", "bsz": "31.4", "num_updates": "17000", "lr": "5.17638e-06", "gnorm": "0", "train_wall": "31", "gb_free": "15.1", "wall": "8217"}
[2024-03-03 22:43:33,072][train_inner][INFO] - {"epoch": 6, "update": 5.165, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "10660.2", "ups": "6.65", "wpb": "1603.9", "bsz": "31.6", "num_updates": "17200", "lr": "5.11212e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8247"}
[2024-03-03 22:44:03,274][train_inner][INFO] - {"epoch": 6, "update": 5.225, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "10610.6", "ups": "6.62", "wpb": "1602.2", "bsz": "31.3", "num_updates": "17400", "lr": "5.04787e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8277"}
[2024-03-03 22:44:33,415][train_inner][INFO] - {"epoch": 6, "update": 5.285, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "10723.1", "ups": "6.64", "wpb": "1616", "bsz": "31.6", "num_updates": "17600", "lr": "4.98361e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8307"}
[2024-03-03 22:45:04,064][train_inner][INFO] - {"epoch": 6, "update": 5.345, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "10417.5", "ups": "6.53", "wpb": "1596.4", "bsz": "31.6", "num_updates": "17800", "lr": "4.91936e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8338"}
[2024-03-03 22:45:34,412][train_inner][INFO] - {"epoch": 6, "update": 5.405, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "10536.9", "ups": "6.59", "wpb": "1598.8", "bsz": "31.5", "num_updates": "18000", "lr": "4.85511e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8368"}
[2024-03-03 22:46:04,480][train_inner][INFO] - {"epoch": 6, "update": 5.465, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "10749.2", "ups": "6.65", "wpb": "1616", "bsz": "31.5", "num_updates": "18200", "lr": "4.79085e-06", "gnorm": "0", "train_wall": "30", "gb_free": "15.1", "wall": "8398"}
[2024-03-03 22:46:33,528][train_inner][INFO] - {"epoch": 6, "update": 5.526, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "10974.2", "ups": "6.89", "wpb": "1593.8", "bsz": "31.6", "num_updates": "18400", "lr": "4.7266e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8427"}
[2024-03-03 22:47:02,976][train_inner][INFO] - {"epoch": 6, "update": 5.586, "loss": "0", "nll_loss": "0", "accuracy": "50.2", "wps": "10910.3", "ups": "6.79", "wpb": "1606.3", "bsz": "31.4", "num_updates": "18600", "lr": "4.66234e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8457"}
[2024-03-03 22:47:32,221][train_inner][INFO] - {"epoch": 6, "update": 5.646, "loss": "0", "nll_loss": "0", "accuracy": "50.3", "wps": "10877", "ups": "6.84", "wpb": "1590.4", "bsz": "31.2", "num_updates": "18800", "lr": "4.59809e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "8486"}
[2024-03-03 22:48:01,077][train_inner][INFO] - {"epoch": 6, "update": 5.706, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "11122.6", "ups": "6.93", "wpb": "1604.7", "bsz": "31.7", "num_updates": "19000", "lr": "4.53383e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "8515"}
[2024-03-03 22:48:30,277][train_inner][INFO] - {"epoch": 6, "update": 5.766, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "11031.9", "ups": "6.85", "wpb": "1610.6", "bsz": "31.5", "num_updates": "19200", "lr": "4.46958e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8544"}
[2024-03-03 22:48:59,958][train_inner][INFO] - {"epoch": 6, "update": 5.826, "loss": "0", "nll_loss": "0", "accuracy": "48.9", "wps": "10791.5", "ups": "6.74", "wpb": "1601.5", "bsz": "31.5", "num_updates": "19400", "lr": "4.40532e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8573"}
[2024-03-03 22:49:28,766][train_inner][INFO] - {"epoch": 6, "update": 5.886, "loss": "0", "nll_loss": "0", "accuracy": "48", "wps": "11121.8", "ups": "6.94", "wpb": "1601.9", "bsz": "31.6", "num_updates": "19600", "lr": "4.34107e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "8602"}
[2024-03-03 22:49:58,048][train_inner][INFO] - {"epoch": 6, "update": 5.946, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "10958.3", "ups": "6.83", "wpb": "1604.4", "bsz": "31.2", "num_updates": "19800", "lr": "4.27681e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "8632"}
[2024-03-03 22:50:23,782][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 22:50:23,784][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:50:47,925][valid][INFO] - {"epoch": 6, "valid_loss": "1.004", "valid_nll_loss": "0.019", "valid_accuracy": "50.6", "valid_wps": "11805.2", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "19980", "valid_best_accuracy": "50.8"}
[2024-03-03 22:50:47,930][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 19980 updates
[2024-03-03 22:50:47,932][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:50:52,100][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:50:52,104][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 6 @ 19980 updates, score 50.6) (writing took 4.174112852999315 seconds)
[2024-03-03 22:50:52,105][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-03-03 22:50:52,107][train][INFO] - {"epoch": 6, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.6", "train_wps": "10190.8", "train_ups": "6.36", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "19980", "train_lr": "4.21898e-06", "train_gnorm": "0", "train_train_wall": "489", "train_gb_free": "15", "train_wall": "8686"}
[2024-03-03 22:50:52,109][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:50:52,114][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 22:50:52,117][fairseq.trainer][INFO] - begin training epoch 7
[2024-03-03 22:50:52,119][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 22:50:55,297][train_inner][INFO] - {"epoch": 7, "update": 6.006, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "5572.2", "ups": "3.49", "wpb": "1595", "bsz": "31.4", "num_updates": "20000", "lr": "4.21256e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "8689"}
[2024-03-03 22:51:24,082][train_inner][INFO] - {"epoch": 7, "update": 6.066, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "11107.1", "ups": "6.95", "wpb": "1598.5", "bsz": "31.2", "num_updates": "20200", "lr": "4.1483e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "8718"}
[2024-03-03 22:51:52,490][train_inner][INFO] - {"epoch": 7, "update": 6.126, "loss": "0", "nll_loss": "0", "accuracy": "50.2", "wps": "11287.7", "ups": "7.04", "wpb": "1603.2", "bsz": "31.5", "num_updates": "20400", "lr": "4.08405e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "8746"}
[2024-03-03 22:52:20,783][train_inner][INFO] - {"epoch": 7, "update": 6.186, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "11300.1", "ups": "7.07", "wpb": "1598.5", "bsz": "31.6", "num_updates": "20600", "lr": "4.01979e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "8774"}
[2024-03-03 22:52:48,704][train_inner][INFO] - {"epoch": 7, "update": 6.246, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "11485.6", "ups": "7.16", "wpb": "1603.4", "bsz": "31.8", "num_updates": "20800", "lr": "3.95554e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "8802"}
[2024-03-03 22:53:17,497][train_inner][INFO] - {"epoch": 7, "update": 6.306, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "11163.4", "ups": "6.95", "wpb": "1607.1", "bsz": "31.5", "num_updates": "21000", "lr": "3.89128e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "8831"}
[2024-03-03 22:53:46,878][train_inner][INFO] - {"epoch": 7, "update": 6.366, "loss": "0", "nll_loss": "0", "accuracy": "48.7", "wps": "10967.2", "ups": "6.81", "wpb": "1611.1", "bsz": "31.4", "num_updates": "21200", "lr": "3.82703e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8860"}
[2024-03-03 22:54:15,388][train_inner][INFO] - {"epoch": 7, "update": 6.426, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "11265.6", "ups": "7.02", "wpb": "1605.9", "bsz": "31.5", "num_updates": "21400", "lr": "3.76277e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "8889"}
[2024-03-03 22:54:44,530][train_inner][INFO] - {"epoch": 7, "update": 6.486, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "10927.9", "ups": "6.86", "wpb": "1592.2", "bsz": "31.4", "num_updates": "21600", "lr": "3.69852e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8918"}
[2024-03-03 22:55:13,809][train_inner][INFO] - {"epoch": 7, "update": 6.547, "loss": "0", "nll_loss": "0", "accuracy": "48.9", "wps": "10900.3", "ups": "6.83", "wpb": "1595.7", "bsz": "31.5", "num_updates": "21800", "lr": "3.63426e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8947"}
[2024-03-03 22:55:42,724][train_inner][INFO] - {"epoch": 7, "update": 6.607, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "11127.4", "ups": "6.92", "wpb": "1608.6", "bsz": "31.4", "num_updates": "22000", "lr": "3.57001e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "8976"}
[2024-03-03 22:56:11,588][train_inner][INFO] - {"epoch": 7, "update": 6.667, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "11130.4", "ups": "6.93", "wpb": "1606.3", "bsz": "31.4", "num_updates": "22200", "lr": "3.50575e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9005"}
[2024-03-03 22:56:40,093][train_inner][INFO] - {"epoch": 7, "update": 6.727, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "11241.1", "ups": "7.02", "wpb": "1602.1", "bsz": "31.5", "num_updates": "22400", "lr": "3.4415e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9034"}
[2024-03-03 22:57:09,051][train_inner][INFO] - {"epoch": 7, "update": 6.787, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "11074.2", "ups": "6.91", "wpb": "1603.4", "bsz": "31.3", "num_updates": "22600", "lr": "3.37724e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "9063"}
[2024-03-03 22:57:37,595][train_inner][INFO] - {"epoch": 7, "update": 6.847, "loss": "0", "nll_loss": "0", "accuracy": "49.9", "wps": "11192", "ups": "7.01", "wpb": "1597.2", "bsz": "31.5", "num_updates": "22800", "lr": "3.31299e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9091"}
[2024-03-03 22:58:05,951][train_inner][INFO] - {"epoch": 7, "update": 6.907, "loss": "0", "nll_loss": "0", "accuracy": "48.9", "wps": "11403.3", "ups": "7.05", "wpb": "1616.7", "bsz": "31.6", "num_updates": "23000", "lr": "3.24873e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9119"}
[2024-03-03 22:58:34,502][train_inner][INFO] - {"epoch": 7, "update": 6.967, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "11108", "ups": "7.01", "wpb": "1585.7", "bsz": "31.3", "num_updates": "23200", "lr": "3.18448e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9148"}
[2024-03-03 22:58:50,179][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 22:58:50,181][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:59:14,521][valid][INFO] - {"epoch": 7, "valid_loss": "1.003", "valid_nll_loss": "0.019", "valid_accuracy": "50.6", "valid_wps": "11710.5", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "23310", "valid_best_accuracy": "50.8"}
[2024-03-03 22:59:14,525][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 23310 updates
[2024-03-03 22:59:14,527][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:59:18,659][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 22:59:18,663][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 7 @ 23310 updates, score 50.6) (writing took 4.138377008999669 seconds)
[2024-03-03 22:59:18,665][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-03-03 22:59:18,669][train][INFO] - {"epoch": 7, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.4", "train_wps": "10532", "train_ups": "6.57", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "23310", "train_lr": "3.14914e-06", "train_gnorm": "0", "train_train_wall": "472", "train_gb_free": "15.1", "train_wall": "9192"}
[2024-03-03 22:59:18,671][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 22:59:18,676][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 22:59:18,679][fairseq.trainer][INFO] - begin training epoch 8
[2024-03-03 22:59:18,680][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 22:59:31,873][train_inner][INFO] - {"epoch": 8, "update": 7.027, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "5553.5", "ups": "3.49", "wpb": "1593", "bsz": "31.6", "num_updates": "23400", "lr": "3.12022e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9205"}
[2024-03-03 23:00:00,313][train_inner][INFO] - {"epoch": 8, "update": 7.087, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "11318.4", "ups": "7.03", "wpb": "1609.4", "bsz": "31.5", "num_updates": "23600", "lr": "3.05597e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9234"}
[2024-03-03 23:00:29,333][train_inner][INFO] - {"epoch": 8, "update": 7.147, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "11103.8", "ups": "6.89", "wpb": "1611.1", "bsz": "31.5", "num_updates": "23800", "lr": "2.99171e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "9263"}
[2024-03-03 23:00:58,490][train_inner][INFO] - {"epoch": 8, "update": 7.207, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "10909.9", "ups": "6.86", "wpb": "1590.4", "bsz": "31.2", "num_updates": "24000", "lr": "2.92746e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "9292"}
[2024-03-03 23:01:26,531][train_inner][INFO] - {"epoch": 8, "update": 7.267, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "11451.5", "ups": "7.13", "wpb": "1605.5", "bsz": "31.7", "num_updates": "24200", "lr": "2.8632e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9320"}
[2024-03-03 23:01:55,263][train_inner][INFO] - {"epoch": 8, "update": 7.327, "loss": "0", "nll_loss": "0", "accuracy": "49.9", "wps": "11148.5", "ups": "6.96", "wpb": "1601.5", "bsz": "31.6", "num_updates": "24400", "lr": "2.79895e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9349"}
[2024-03-03 23:02:23,779][train_inner][INFO] - {"epoch": 8, "update": 7.387, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "11105.3", "ups": "7.01", "wpb": "1583.3", "bsz": "31.5", "num_updates": "24600", "lr": "2.73469e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9377"}
[2024-03-03 23:02:52,186][train_inner][INFO] - {"epoch": 8, "update": 7.447, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "11340.9", "ups": "7.04", "wpb": "1610.7", "bsz": "31.5", "num_updates": "24800", "lr": "2.67044e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9406"}
[2024-03-03 23:03:20,578][train_inner][INFO] - {"epoch": 8, "update": 7.508, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "11309.1", "ups": "7.04", "wpb": "1605.4", "bsz": "31.6", "num_updates": "25000", "lr": "2.60618e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9434"}
[2024-03-03 23:03:49,623][train_inner][INFO] - {"epoch": 8, "update": 7.568, "loss": "0", "nll_loss": "0", "accuracy": "50.2", "wps": "11013.4", "ups": "6.89", "wpb": "1599.3", "bsz": "31.4", "num_updates": "25200", "lr": "2.54193e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "9463"}
[2024-03-03 23:04:18,545][train_inner][INFO] - {"epoch": 8, "update": 7.628, "loss": "0", "nll_loss": "0", "accuracy": "49.9", "wps": "11085.4", "ups": "6.92", "wpb": "1603", "bsz": "31.4", "num_updates": "25400", "lr": "2.47767e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "9492"}
[2024-03-03 23:04:47,232][train_inner][INFO] - {"epoch": 8, "update": 7.688, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "11106.6", "ups": "6.97", "wpb": "1593", "bsz": "31.3", "num_updates": "25600", "lr": "2.41342e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "9521"}
[2024-03-03 23:05:15,619][train_inner][INFO] - {"epoch": 8, "update": 7.748, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "11233.3", "ups": "7.05", "wpb": "1594.3", "bsz": "31.4", "num_updates": "25800", "lr": "2.34916e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9549"}
[2024-03-03 23:05:44,728][train_inner][INFO] - {"epoch": 8, "update": 7.808, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "11017.2", "ups": "6.87", "wpb": "1603.5", "bsz": "31.1", "num_updates": "26000", "lr": "2.28491e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "9578"}
[2024-03-03 23:06:13,323][train_inner][INFO] - {"epoch": 8, "update": 7.868, "loss": "0", "nll_loss": "0", "accuracy": "49.1", "wps": "11263.6", "ups": "6.99", "wpb": "1610.3", "bsz": "31.4", "num_updates": "26200", "lr": "2.22065e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9607"}
[2024-03-03 23:06:42,236][train_inner][INFO] - {"epoch": 8, "update": 7.928, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "11110.2", "ups": "6.92", "wpb": "1606.1", "bsz": "31.4", "num_updates": "26400", "lr": "2.1564e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "9636"}
[2024-03-03 23:07:10,437][train_inner][INFO] - {"epoch": 8, "update": 7.988, "loss": "0", "nll_loss": "0", "accuracy": "50.2", "wps": "11469.1", "ups": "7.09", "wpb": "1617.1", "bsz": "31.7", "num_updates": "26600", "lr": "2.09214e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9664"}
[2024-03-03 23:07:15,845][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 23:07:15,846][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 23:07:39,880][valid][INFO] - {"epoch": 8, "valid_loss": "1.003", "valid_nll_loss": "0.019", "valid_accuracy": "50.7", "valid_wps": "11859.6", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "26640", "valid_best_accuracy": "50.8"}
[2024-03-03 23:07:39,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 26640 updates
[2024-03-03 23:07:39,886][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 23:07:44,011][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_last.pt
[2024-03-03 23:07:44,014][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 8 @ 26640 updates, score 50.7) (writing took 4.129314809999414 seconds)
[2024-03-03 23:07:44,015][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-03-03 23:07:44,019][train][INFO] - {"epoch": 8, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.6", "train_wps": "10557.2", "train_ups": "6.59", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "26640", "train_lr": "2.07929e-06", "train_gnorm": "0", "train_train_wall": "471", "train_gb_free": "15.1", "train_wall": "9698"}
[2024-03-03 23:07:44,021][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 23:07:44,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 23:07:44,030][fairseq.trainer][INFO] - begin training epoch 9
[2024-03-03 23:07:44,031][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 23:08:07,390][train_inner][INFO] - {"epoch": 9, "update": 8.048, "loss": "0", "nll_loss": "0", "accuracy": "48.7", "wps": "5644.2", "ups": "3.51", "wpb": "1607.2", "bsz": "31.5", "num_updates": "26800", "lr": "2.02789e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9721"}
[2024-03-03 23:08:35,913][train_inner][INFO] - {"epoch": 9, "update": 8.108, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "11329", "ups": "7.01", "wpb": "1615.6", "bsz": "31.7", "num_updates": "27000", "lr": "1.96363e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9749"}
[2024-03-03 23:09:04,702][train_inner][INFO] - {"epoch": 9, "update": 8.168, "loss": "0", "nll_loss": "0", "accuracy": "48.9", "wps": "11083", "ups": "6.95", "wpb": "1595.3", "bsz": "31.4", "num_updates": "27200", "lr": "1.89938e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "9778"}
[2024-03-03 23:09:32,985][train_inner][INFO] - {"epoch": 9, "update": 8.228, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "11241.7", "ups": "7.07", "wpb": "1589.7", "bsz": "31.4", "num_updates": "27400", "lr": "1.83512e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9807"}
[2024-03-03 23:10:01,290][train_inner][INFO] - {"epoch": 9, "update": 8.288, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "11321.8", "ups": "7.07", "wpb": "1602.3", "bsz": "31.3", "num_updates": "27600", "lr": "1.77087e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9835"}
[2024-03-03 23:10:29,127][train_inner][INFO] - {"epoch": 9, "update": 8.348, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "11465.2", "ups": "7.19", "wpb": "1595.7", "bsz": "31.6", "num_updates": "27800", "lr": "1.70661e-06", "gnorm": "0", "train_wall": "27", "gb_free": "15.1", "wall": "9863"}
[2024-03-03 23:10:57,606][train_inner][INFO] - {"epoch": 9, "update": 8.408, "loss": "0", "nll_loss": "0", "accuracy": "50.4", "wps": "11375.7", "ups": "7.02", "wpb": "1619.8", "bsz": "31.6", "num_updates": "28000", "lr": "1.64236e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "9891"}
[2024-03-03 23:11:26,100][train_inner][INFO] - {"epoch": 9, "update": 8.468, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "11224.6", "ups": "7.02", "wpb": "1599.1", "bsz": "31.5", "num_updates": "28200", "lr": "1.5781e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9920"}
[2024-03-03 23:11:55,173][train_inner][INFO] - {"epoch": 9, "update": 8.529, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "11001.4", "ups": "6.88", "wpb": "1599.2", "bsz": "31.4", "num_updates": "28400", "lr": "1.51385e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "9949"}
[2024-03-03 23:12:23,885][train_inner][INFO] - {"epoch": 9, "update": 8.589, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "11197.5", "ups": "6.97", "wpb": "1607.5", "bsz": "31.4", "num_updates": "28600", "lr": "1.44959e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "9977"}
[2024-03-03 23:12:52,527][train_inner][INFO] - {"epoch": 9, "update": 8.649, "loss": "0", "nll_loss": "0", "accuracy": "49.5", "wps": "11203.3", "ups": "6.98", "wpb": "1604.3", "bsz": "31.5", "num_updates": "28800", "lr": "1.38534e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10006"}
[2024-03-03 23:13:21,092][train_inner][INFO] - {"epoch": 9, "update": 8.709, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "11237.4", "ups": "7", "wpb": "1604.9", "bsz": "31.4", "num_updates": "29000", "lr": "1.32108e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10035"}
[2024-03-03 23:13:50,812][train_inner][INFO] - {"epoch": 9, "update": 8.769, "loss": "0", "nll_loss": "0", "accuracy": "49.2", "wps": "10746.4", "ups": "6.73", "wpb": "1596.8", "bsz": "31.3", "num_updates": "29200", "lr": "1.25683e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "10064"}
[2024-03-03 23:14:19,405][train_inner][INFO] - {"epoch": 9, "update": 8.829, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "11218.5", "ups": "7", "wpb": "1603.8", "bsz": "31.5", "num_updates": "29400", "lr": "1.19257e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10093"}
[2024-03-03 23:14:48,401][train_inner][INFO] - {"epoch": 9, "update": 8.889, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "11110.5", "ups": "6.9", "wpb": "1610.8", "bsz": "31.6", "num_updates": "29600", "lr": "1.12832e-06", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "10122"}
[2024-03-03 23:15:17,093][train_inner][INFO] - {"epoch": 9, "update": 8.949, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "11113.4", "ups": "6.97", "wpb": "1594.2", "bsz": "31.3", "num_updates": "29800", "lr": "1.06406e-06", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "10151"}
[2024-03-03 23:15:41,370][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 23:15:41,372][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 23:16:05,521][valid][INFO] - {"epoch": 9, "valid_loss": "1.003", "valid_nll_loss": "0.019", "valid_accuracy": "50.8", "valid_wps": "11802.6", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "29970", "valid_best_accuracy": "50.8"}
[2024-03-03 23:16:05,526][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 29970 updates
[2024-03-03 23:16:05,528][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 23:16:10,231][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 23:16:49,016][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 9 @ 29970 updates, score 50.8) (writing took 43.48998482299976 seconds)
[2024-03-03 23:16:49,017][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-03-03 23:16:49,708][train][INFO] - {"epoch": 9, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.5", "train_wps": "9776.8", "train_ups": "6.1", "train_wpb": "1602.1", "train_bsz": "31.5", "train_num_updates": "29970", "train_lr": "1.00945e-06", "train_gnorm": "0", "train_train_wall": "471", "train_gb_free": "15.1", "train_wall": "10243"}
[2024-03-03 23:16:49,711][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 23:16:49,717][fairseq.data.iterators][INFO] - grouped total_num_itrs = 3330
[2024-03-03 23:16:49,720][fairseq.trainer][INFO] - begin training epoch 10
[2024-03-03 23:16:49,721][fairseq_cli.train][INFO] - Start iterating over samples
[2024-03-03 23:16:53,932][train_inner][INFO] - {"epoch": 10, "update": 9.009, "loss": "0", "nll_loss": "0", "accuracy": "50.1", "wps": "3272.7", "ups": "2.07", "wpb": "1584.6", "bsz": "31.5", "num_updates": "30000", "lr": "9.99807e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10247"}
[2024-03-03 23:17:19,714][train_inner][INFO] - {"epoch": 10, "update": 9.069, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "12509.3", "ups": "7.76", "wpb": "1612.6", "bsz": "31.6", "num_updates": "30200", "lr": "9.35552e-07", "gnorm": "0", "train_wall": "25", "gb_free": "15.1", "wall": "10273"}
[2024-03-03 23:17:45,808][train_inner][INFO] - {"epoch": 10, "update": 9.129, "loss": "0", "nll_loss": "0", "accuracy": "49", "wps": "12288.2", "ups": "7.67", "wpb": "1603.1", "bsz": "31.6", "num_updates": "30400", "lr": "8.71297e-07", "gnorm": "0", "train_wall": "26", "gb_free": "15.1", "wall": "10299"}
[2024-03-03 23:18:14,291][train_inner][INFO] - {"epoch": 10, "update": 9.189, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "11333.3", "ups": "7.02", "wpb": "1614", "bsz": "31.3", "num_updates": "30600", "lr": "8.07042e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "10328"}
[2024-03-03 23:18:42,231][train_inner][INFO] - {"epoch": 10, "update": 9.249, "loss": "0", "nll_loss": "0", "accuracy": "49.6", "wps": "11438.9", "ups": "7.16", "wpb": "1597.9", "bsz": "31.4", "num_updates": "30800", "lr": "7.42787e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10356"}
[2024-03-03 23:19:11,024][train_inner][INFO] - {"epoch": 10, "update": 9.309, "loss": "0", "nll_loss": "0", "accuracy": "49.7", "wps": "11093.4", "ups": "6.95", "wpb": "1597", "bsz": "31.3", "num_updates": "31000", "lr": "6.78532e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10385"}
[2024-03-03 23:19:39,154][train_inner][INFO] - {"epoch": 10, "update": 9.369, "loss": "0", "nll_loss": "0", "accuracy": "49.3", "wps": "11418", "ups": "7.11", "wpb": "1605.9", "bsz": "31.6", "num_updates": "31200", "lr": "6.14277e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10413"}
[2024-03-03 23:20:07,613][train_inner][INFO] - {"epoch": 10, "update": 9.429, "loss": "0", "nll_loss": "0", "accuracy": "50.6", "wps": "11219.8", "ups": "7.03", "wpb": "1596.5", "bsz": "31.2", "num_updates": "31400", "lr": "5.50022e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10441"}
[2024-03-03 23:20:35,530][train_inner][INFO] - {"epoch": 10, "update": 9.489, "loss": "0", "nll_loss": "0", "accuracy": "48.7", "wps": "11448.2", "ups": "7.16", "wpb": "1597.9", "bsz": "31.6", "num_updates": "31600", "lr": "4.85768e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10469"}
[2024-03-03 23:21:04,549][train_inner][INFO] - {"epoch": 10, "update": 9.55, "loss": "0", "nll_loss": "0", "accuracy": "48.2", "wps": "10981.7", "ups": "6.89", "wpb": "1593.4", "bsz": "31.3", "num_updates": "31800", "lr": "4.21513e-07", "gnorm": "0", "train_wall": "29", "gb_free": "15", "wall": "10498"}
[2024-03-03 23:21:33,537][train_inner][INFO] - {"epoch": 10, "update": 9.61, "loss": "0", "nll_loss": "0", "accuracy": "49.8", "wps": "11052", "ups": "6.9", "wpb": "1601.8", "bsz": "31.3", "num_updates": "32000", "lr": "3.57258e-07", "gnorm": "0", "train_wall": "29", "gb_free": "15.1", "wall": "10527"}
[2024-03-03 23:22:01,932][train_inner][INFO] - {"epoch": 10, "update": 9.67, "loss": "0", "nll_loss": "0", "accuracy": "49.4", "wps": "11267", "ups": "7.04", "wpb": "1599.6", "bsz": "31.4", "num_updates": "32200", "lr": "2.93003e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10555"}
[2024-03-03 23:22:29,871][train_inner][INFO] - {"epoch": 10, "update": 9.73, "loss": "0", "nll_loss": "0", "accuracy": "48.8", "wps": "11512.2", "ups": "7.16", "wpb": "1608.1", "bsz": "31.6", "num_updates": "32400", "lr": "2.28748e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10583"}
[2024-03-03 23:22:58,344][train_inner][INFO] - {"epoch": 10, "update": 9.79, "loss": "0", "nll_loss": "0", "accuracy": "50", "wps": "11204.2", "ups": "7.02", "wpb": "1595", "bsz": "31.4", "num_updates": "32600", "lr": "1.64493e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10612"}
[2024-03-03 23:23:26,972][train_inner][INFO] - {"epoch": 10, "update": 9.85, "loss": "0", "nll_loss": "0", "accuracy": "49.9", "wps": "11241.2", "ups": "6.99", "wpb": "1609", "bsz": "31.6", "num_updates": "32800", "lr": "1.00238e-07", "gnorm": "0", "train_wall": "28", "gb_free": "15.1", "wall": "10641"}
[2024-03-03 23:23:55,368][train_inner][INFO] - {"epoch": 10, "update": 9.91, "loss": "0", "nll_loss": "0", "accuracy": "50.3", "wps": "11252.8", "ups": "7.04", "wpb": "1597.6", "bsz": "31.6", "num_updates": "33000", "lr": "3.59828e-08", "gnorm": "0", "train_wall": "28", "gb_free": "15", "wall": "10669"}
[2024-03-03 23:24:11,839][fairseq_cli.train][INFO] - Stopping training due to num_updates: 33112 >= max_update: 33112
[2024-03-03 23:24:11,840][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2024-03-03 23:24:11,841][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2024-03-03 23:24:35,798][valid][INFO] - {"epoch": 10, "valid_loss": "1.003", "valid_nll_loss": "0.019", "valid_accuracy": "50.8", "valid_wps": "11896", "valid_wpb": "1626.9", "valid_bsz": "31.2", "valid_num_updates": "33112", "valid_best_accuracy": "50.8"}
[2024-03-03 23:24:35,801][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 33112 updates
[2024-03-03 23:24:35,803][fairseq.trainer][INFO] - Saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 23:24:39,424][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/c/Users/yifei/OneDrive/桌面/CS8803EML/eml-hw2/fairseq/outputs/2024-03-03/20-26-00/checkpoints/checkpoint_best.pt
[2024-03-03 23:25:15,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 33112 updates, score 50.8) (writing took 39.25686961000065 seconds)
[2024-03-03 23:25:15,059][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-03-03 23:25:15,749][train][INFO] - {"epoch": 10, "train_loss": "0", "train_nll_loss": "0", "train_accuracy": "49.5", "train_wps": "9947.8", "train_ups": "6.21", "train_wpb": "1602.2", "train_bsz": "31.5", "train_num_updates": "33112", "train_lr": "0", "train_gnorm": "0", "train_train_wall": "437", "train_gb_free": "15.1", "train_wall": "10749"}
[2024-03-03 23:25:15,750][fairseq_cli.train][INFO] - done training in 10736.6 seconds
